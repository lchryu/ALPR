import cv2
import numpy as np
import re
import easyocr

# Create reader 1 l·∫ßn (t·ªëi ∆∞u)
reader = easyocr.Reader(['en'])

# ----------------------------------------------------------
# Detect if plate is 2-line or 1-line based on aspect ratio
# ----------------------------------------------------------
def is_two_line_plate(crop):
    h, w = crop.shape[:2]
    ratio = w / h
    return ratio < 3.2

# ----------------------------------------------------------
# Split 2-line motorcycle plate
# ----------------------------------------------------------
def split_two_line_plate(crop):
    h, w = crop.shape[:2]
    mid = h // 2
    return crop[0:mid, :], crop[mid:h, :]

# ----------------------------------------------------------
# Preprocess - T·ªëi ∆∞u cho EasyOCR
# ----------------------------------------------------------
def preprocess(crop):
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc t·ªëi thi·ªÉu
    h, w = crop.shape[:2]
    
    # Upscale th√¥ng minh: n·∫øu ·∫£nh qu√° nh·ªè th√¨ scale l·ªõn h∆°n
    if min(h, w) < 50:
        scale = 4.0
    elif min(h, w) < 100:
        scale = 3.0
    else:
        scale = 2.5
    
    # Resize v·ªõi interpolation t·ªët
    crop = cv2.resize(crop, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
    
    # Convert to grayscale
    if len(crop.shape) == 3:
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    else:
        gray = crop.copy()
    
    # Denoise v·ªõi Non-local Means (t·ªët h∆°n bilateral cho text)
    # N·∫øu ·∫£nh qu√° nh·ªè th√¨ d√πng bilateral thay v√¨ NLM (NLM ch·∫≠m)
    if min(gray.shape) > 100:
        gray = cv2.fastNlMeansDenoising(gray, h=10, templateWindowSize=7, searchWindowSize=21)
    else:
        gray = cv2.bilateralFilter(gray, 5, 50, 50)
    
    # CLAHE (Contrast Limited Adaptive Histogram Equalization) - t·ªët h∆°n equalizeHist
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    
    # Adaptive threshold ƒë·ªÉ t·∫°o binary image (t√πy ch·ªçn)
    # Th·ª≠ adaptive threshold ƒë·ªÉ t√°ch foreground/background t·ªët h∆°n
    adaptive_thresh = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 11, 2
    )
    
    # Morphological operations ƒë·ªÉ l√†m s·∫°ch
    # ƒê√≥ng c√°c l·ªó nh·ªè trong ch·ªØ
    kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    adaptive_thresh = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel_close)
    
    # M·ªü ƒë·ªÉ lo·∫°i b·ªè noise nh·ªè
    kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
    adaptive_thresh = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_OPEN, kernel_open)
    
    # Blend: 60% adaptive threshold + 40% CLAHE gray
    # Adaptive threshold gi√∫p t√°ch ch·ªØ r√µ, CLAHE gi·ªØ texture
    final = cv2.addWeighted(adaptive_thresh, 0.6, gray, 0.4, 0)
    
    # Sharpen nh·∫π ƒë·ªÉ l√†m n√©t ch·ªØ
    kernel_sharpen = np.array([
        [0, -1, 0],
        [-1, 5, -1],
        [0, -1, 0]
    ])
    final = cv2.filter2D(final, -1, kernel_sharpen)
    
    # Normalize v·ªÅ [0, 255]
    final = np.clip(final, 0, 255).astype(np.uint8)
    
    return final

# ----------------------------------------------------------
# Detect v√† t√°ch t·ª´ng k√Ω t·ª± trong bi·ªÉn s·ªë
# ----------------------------------------------------------
def detect_characters(preprocessed_img):
    """
    T√°ch t·ª´ng k√Ω t·ª± t·ª´ ·∫£nh ƒë√£ preprocess b·∫±ng contour detection
    Returns: list of (x, y, w, h, char_img) - sorted t·ª´ tr√°i sang ph·∫£i
    """
    # T·∫°o binary image ƒë·ªÉ t√¨m contours
    # Th·ª≠ nhi·ªÅu c√°ch ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t
    _, binary1 = cv2.threshold(preprocessed_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    binary2 = cv2.adaptiveThreshold(
        preprocessed_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 11, 2
    )
    
    # D√πng binary t·ªët h∆°n (th∆∞·ªùng Otsu t·ªët h∆°n)
    binary = binary1
    
    # Morphological operations ƒë·ªÉ n·ªëi c√°c ph·∫ßn c·ªßa k√Ω t·ª± b·ªã t√°ch
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    
    # T√¨m contours
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    char_boxes = []
    h_img, w_img = preprocessed_img.shape[:2]
    
    # L·ªçc v√† l∆∞u c√°c bounding box c·ªßa k√Ω t·ª±
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        
        # L·ªçc noise: b·ªè c√°c box qu√° nh·ªè ho·∫∑c qu√° l·ªõn
        area = w * h
        img_area = h_img * w_img
        min_area = img_area * 0.005  # 0.5% di·ªán t√≠ch ·∫£nh (gi·∫£m ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c k√Ω t·ª± nh·ªè)
        max_area = img_area * 0.25   # 25% di·ªán t√≠ch ·∫£nh
        
        # L·ªçc theo aspect ratio (k√Ω t·ª± th∆∞·ªùng c√≥ ratio h·ª£p l√Ω)
        aspect_ratio = h / w if w > 0 else 0
        
        # Chi·ªÅu cao t·ªëi thi·ªÉu (gi·∫£m xu·ªëng ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c k√Ω t·ª± nh·ªè h∆°n)
        min_height = h_img * 0.25  # 25% chi·ªÅu cao ·∫£nh
        
        if (min_area < area < max_area and 
            0.3 < aspect_ratio < 4.0 and  # M·ªü r·ªông range cho aspect ratio
            h > min_height and
            w > 3 and h > 3):  # K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu tuy·ªát ƒë·ªëi
            # Th√™m padding
            padding = max(3, min(w, h) // 5)
            x = max(0, x - padding)
            y = max(0, y - padding)
            w = min(w_img - x, w + 2 * padding)
            h = min(h_img - y, h + 2 * padding)
            
            char_img = preprocessed_img[y:y+h, x:x+w]
            char_boxes.append((x, y, w, h, char_img))
    
    # S·∫Øp x·∫øp t·ª´ tr√°i sang ph·∫£i (theo x)
    char_boxes.sort(key=lambda box: box[0])
    
    return char_boxes

# ----------------------------------------------------------
# OCR m·ªôt k√Ω t·ª± ƒë∆°n l·∫ª
# ----------------------------------------------------------
def ocr_single_char(char_img):
    """
    OCR m·ªôt k√Ω t·ª± ƒë∆°n l·∫ª v·ªõi confidence cao h∆°n
    """
    # Th√™m padding tr·∫Øng xung quanh ƒë·ªÉ EasyOCR ƒë·ªçc t·ªët h∆°n
    h, w = char_img.shape[:2]
    padding = max(10, min(h, w) // 4)
    padded = cv2.copyMakeBorder(
        char_img, padding, padding, padding, padding,
        cv2.BORDER_CONSTANT, value=255
    )
    
    # OCR v·ªõi detail ƒë·ªÉ l·∫•y confidence
    results = reader.readtext(padded, detail=1, paragraph=False)
    
    if not results:
        return "", 0.0
    
    # L·∫•y k·∫øt qu·∫£ c√≥ confidence cao nh·∫•t
    best_result = max(results, key=lambda x: x[2])
    char = best_result[1].strip()
    conf = best_result[2]
    
    return char, conf

# ----------------------------------------------------------
# OCR to√†n b·ªô bi·ªÉn b·∫±ng c√°ch OCR t·ª´ng k√Ω t·ª±
# ----------------------------------------------------------
def ocr_by_characters(preprocessed_img):
    """
    OCR bi·ªÉn s·ªë b·∫±ng c√°ch detect v√† OCR t·ª´ng k√Ω t·ª± ri√™ng l·∫ª
    Returns: (raw_text, normalized_text, char_details)
    """
    char_boxes = detect_characters(preprocessed_img)
    
    if not char_boxes:
        # N·∫øu kh√¥ng detect ƒë∆∞·ª£c k√Ω t·ª±, fallback v·ªÅ OCR to√†n b·ªô
        raw = ocr_text(preprocessed_img)
        return raw, normalize(raw), []
    
    chars = []
    char_details = []
    
    for x, y, w, h, char_img in char_boxes:
        char, conf = ocr_single_char(char_img)
        if char:
            chars.append(char)
            char_details.append({
                'char': char,
                'bbox': (x, y, w, h),
                'conf': conf
            })
    
    raw_text = "".join(chars)
    normalized_text = normalize(raw_text)
    
    return raw_text, normalized_text, char_details

# ----------------------------------------------------------
# üî• OCR b·∫±ng EasyOCR (thay Tesseract) - Fallback method
# ----------------------------------------------------------
def ocr_text(img):
    results = reader.readtext(img, detail=0)
    if not results:
        return ""
    return "".join(results)

# ----------------------------------------------------------
# Normalize plate - D√πng regex ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
# ----------------------------------------------------------
def normalize(t):
    if not t:
        return ""
    
    # Chuy·ªÉn sang uppercase
    t = t.upper()
    
    # D√πng regex ƒë·ªÉ lo·∫°i b·ªè t·∫•t c·∫£ k√Ω t·ª± ƒë·∫∑c bi·ªát (. - _ space v√† c√°c k√Ω t·ª± kh√°c)
    # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i v√† s·ªë
    t = re.sub(r"[^A-Z0-9]", "", t)
    
    # Thay th·∫ø c√°c k√Ω t·ª± d·ªÖ nh·∫ßm l·∫´n
    replacements = {
        "O": "0",  # O -> 0
        "I": "1",  # I -> 1
        "Z": "2",  # Z -> 2
        "S": "5",  # S -> 5
        "B": "8",  # B -> 8
    }
    
    for old, new in replacements.items():
        t = t.replace(old, new)
    
    return t
